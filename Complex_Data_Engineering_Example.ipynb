{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complex Data Engineering Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/todnewman/outlace.github.io/blob/master/Complex_Data_Engineering_Example.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "5o4LRj4uXwlj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Complex Data Handling Example\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this example, we do a few useful things that will be valuable as examples for how to clean and join data sources.  The data in this example comes from pro-football-reference.com, a site that is commonly scraped for fantasy football data.\n",
        "\n",
        "The primary tool used here is Pandas, which is the python technique for building and manipulating dataframes.  Specifically, Pandas has a from_html method that can directly parse web tables.  This can be very useful for a number of data scraping activities because web tables can be a bit tricky.\n",
        "\n",
        "## Data Description\n",
        "\n",
        "For this example, we are blending two different types of tables from the site.  \n",
        "\n",
        "*   The first table captures data for all players who had at least one rushing carry.  This means there are multiple positions represented in this table.\n",
        "*   The second table captures data for all players who had receptions.  This means there is some overlap between this table and the rushing table.  \n",
        "\n",
        "## Challenges\n",
        "\n",
        "1.   Dealing with the overlap beween the two tables without duplication and without adding new features is important for developing good features that can be used for ML.  We redefine the headers ourselves to ensure we have good control of this.\n",
        "2.   Doing the math and advanced lookups to build the labels (High Value record vs. Low Value record) from the existing data records is tricky and can be extremely time consuming if done in Excel offline.  Here I show examples of how to automate this.\n",
        "3.   Cleanup of the data, filling holes, etc. is also repeatedly demonstrated.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "CdlDSNJPQd_0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install lxml\n",
        "\n",
        "This step is needed to use the Pandas from_html method.  "
      ]
    },
    {
      "metadata": {
        "id": "EwH5xMJg1fYR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26adabb3-5b54-431d-dded-eed98ecbf41f"
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.4)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VTWlfFRW1gcn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import lxml\n",
        "import html5lib\n",
        "import pandas as pd\n",
        "\n",
        "#\n",
        "# Below we build a list that we'll use to pull multiple years of data from the web.\n",
        "# I do this because its easier than typing up a list of all these years.\n",
        "#\n",
        "\n",
        "yr_list = []\n",
        "for year in range(1992,2018):\n",
        "  yr_list.append(year)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caMhrpQ7SY94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scrape Rushing Data Tables from the Web.\n",
        "\n",
        "Grab data from the Rushing Leaders table for each year in our list.  Then we process and clean the data.  Calculating the score is best done here since the parameters differ across the types of tables on this site.  I also take this chance to strip off the special characters.  \n",
        "\n",
        "This rushing data is interesing because it contains both rushing and receiving metrics."
      ]
    },
    {
      "metadata": {
        "id": "TlBqJMMs1rX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Grab data from the Rushing Leaders table for each year in our list.  Then we process and clean the data.  Calculating the score is best done here since the parameters\n",
        "differ across the types of tables on this site.  I also take this chance to strip off the special characters.  This rushing data is interesing because it contains both\n",
        "rushing and receiving metrics.  \n",
        "'''\n",
        "\n",
        "header = ['Rk', 'NAME', 'Team', 'Age', 'Pos', 'G', 'GS', 'Att', 'Rush Yds', 'Rushing TD', 'Rush Long', 'Y/A', 'Rush Y/G','A/G', 'Tgt', 'Rec', 'Rec Yds', 'Y/R', 'Rec TD', 'Rec Long',\n",
        "          'R/G', 'Y/G', 'Catch%', 'Touch', 'APYd', 'Y/Tch', 'Yscm', 'RRTD', 'Fmb']\n",
        "df_rush = pd.DataFrame()\n",
        "\n",
        "for year in yr_list:\n",
        "    filename = (\"https://www.pro-football-reference.com/years/%s/rushing.htm\" % year)\n",
        "\n",
        "    tables = pd.read_html(filename, header=0)\n",
        "\n",
        "    df_r = tables[0]\n",
        "    df_r.columns = header\n",
        "    df_r['Year'] = year\n",
        "    df_rush = df_rush.append(df_r)    \n",
        "filter = df_rush['Rk']=='Rk'\n",
        "df_rush = df_rush[~filter]\n",
        "df_rush = df_rush.fillna(0)\n",
        "df_rush['Score'] = df_rush['Rush Yds'].astype(int)*.07 + df_rush['Rec Yds'].astype(int)*0.07 + df_rush['RRTD'].astype(int)*6 + df_rush['Rec'].astype(int)*0.5 - df_rush['Fmb'].astype(int)*2\n",
        "#\n",
        "# Remove strange characters from the right of the name using rstrip\n",
        "#\n",
        "df_rush['NAME'] = df_rush['NAME'].map(lambda x: x.rstrip('*'))\n",
        "df_rush['NAME'] = df_rush['NAME'].map(lambda x: x.rstrip('+'))\n",
        "df_rush['NAME'] = df_rush['NAME'].map(lambda x: x.rstrip('*'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8AjzjAUdTAT4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scrape Receiving Data Tables from the Web.\n",
        "\n",
        "Grab data from the Receiving Leaders table for each year in our list.  Then we process and clean the data.  Calculating the score is best done here since the parameters differ across the types of tables on this site.  I also take this chance to strip off the special characters.  \n",
        "\n",
        "This data only has receiving metrics.  There are some players in this data set who didn't rush a single yard and are therefore not captured in the rushing data already."
      ]
    },
    {
      "metadata": {
        "id": "YSoVHmHu1tuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Grab data from the Receiving Leaders table for each year in our list.  Then we process and clean the data.  Calculating the score is best done here since the parameters\n",
        "differ across the types of tables on this site.  I also take this chance to strip off the special characters.  This data only has receiving metrics.  There are some\n",
        "players in this data set who didn't rush a single yard and are therefore not captured in the rushing data already.\n",
        "'''\n",
        "\n",
        "header = ['Rk', 'NAME', 'Team', 'Age', 'Pos', 'G', 'GS', 'Tgt', 'Rec', 'Catch%', 'Rec Yds', 'Y/R', 'Rec TD', 'Rec Long',\n",
        "          'R/G', 'Y/G', 'Fmb']\n",
        "df_rec = pd.DataFrame()\n",
        "for year in yr_list:\n",
        "    filename = (\"https://www.pro-football-reference.com/years/%s/receiving.htm\" % year)\n",
        "\n",
        "    tables = pd.read_html(filename, header=0)\n",
        "\n",
        "    df_r = tables[0]\n",
        "    df_r.columns = header\n",
        "    df_r['Year'] = year\n",
        "    df_rec = df_rec.append(df_r)\n",
        "filter = df_rec['Rk']=='Rk'\n",
        "df_rec = df_rec[~filter]\n",
        "df_rec = df_rec.fillna(0)\n",
        "df_rec['Score'] = df_rec['Rec Yds'].astype(int)*0.07 + df_rec['Rec TD'].astype(int)*6 + df_rec['Rec'].astype(int)*0.5 - df_rec['Fmb'].astype(int)*2\n",
        "#\n",
        "# Remove strange characters from the right of the name using rstrip\n",
        "#\n",
        "df_rec['NAME'] = df_rec['NAME'].map(lambda x: x.rstrip('*'))\n",
        "df_rec['NAME'] = df_rec['NAME'].map(lambda x: x.rstrip('+'))\n",
        "df_rec['NAME'] = df_rec['NAME'].map(lambda x: x.rstrip('*'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rgwt_ip0Toh6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Concatenate Rushing and Receiving DataFrames\n",
        "\n",
        "Here is where we concatenate the rushing dataframe with the records from the receiving dataframe that are NOT included in the rushing dataframe."
      ]
    },
    {
      "metadata": {
        "id": "7RtLIlT9-iFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Here is where we concatenate the rushing dataframe with the records from the receiving dataframe\n",
        "that are NOT included in the rushing dataframe.\n",
        "'''\n",
        "\n",
        "target_value = 160  # This is the score above which we'll classify as a \"high value\" record\n",
        "\n",
        "#\n",
        "# Create a new key combined of name and year to determine how to join dataframes\n",
        "#\n",
        "df_rec['NEWKEY'] = df_rec['NAME'] + df_rec['Year'].astype(str)\n",
        "df_rush['NEWKEY'] = df_rush['NAME'] + df_rush['Year'].astype(str)\n",
        "filter = df_rec['NEWKEY'].isin(df_rush['NEWKEY'])\n",
        "\n",
        "#\n",
        "# Here's the new dataframe that contains all receivers not already in the rushing dataframe\n",
        "#\n",
        "df_rush_rec = df_rec[~filter]\n",
        "\n",
        "#\n",
        "# Concatenate the Rushing and the remnant of the Receiving dataframes\n",
        "#\n",
        "df3 = pd.concat([df_rush, df_rush_rec], axis=0)\n",
        "df3.drop('NEWKEY', axis=1,inplace=True) # Get rid of this temporary feature\n",
        "\n",
        "#\n",
        "# Next, walk through the new dataframe and for each record, gather following year\n",
        "# score and previous year score.\n",
        "#\n",
        "next_year_list = []\n",
        "prev_year_list = []\n",
        "\n",
        "for index,row in df3.iterrows():\n",
        "    \n",
        "    name = row['NAME']\n",
        "    year = row['Year']\n",
        "    \n",
        "    next_year_filter = (df3['NAME'] == name) & (df3['Year'].astype(int) == year + 1)\n",
        "    prev_year_filter = (df3['NAME'] == name) & (df3['Year'].astype(int) == year - 1)\n",
        "    \n",
        "    next_year_list.append(df3[next_year_filter]['Score'].values)\n",
        "    prev_year_list.append(df3[prev_year_filter]['Score'].values)\n",
        "    \n",
        "#\n",
        "# Here we evaluate every record and determine if it is a \"high-value\" example\n",
        "# or a \"low-value\" example.\n",
        "#\n",
        "df3['Target'] = 0 # Initialize new feature to zero\n",
        "target_list = []\n",
        "\n",
        "for index,row in df3.iterrows():    \n",
        "    if row['Following Year Value'] >= target_value:\n",
        "        target_list.append(1)\n",
        "    else:\n",
        "        target_list.append(0)\n",
        "    \n",
        "#\n",
        "# Capture the lists we built above into the new dataframe\n",
        "#\n",
        "    \n",
        "df3['Prev Year Value'] = prev_year_list\n",
        "df3['Following Year Value'] = next_year_list\n",
        "df3['Prev Year Value'] = df3['Prev Year Value'].str[0].fillna(0)\n",
        "df3['Following Year Value'] = df3['Following Year Value'].str[0].fillna(0)\n",
        "df3['Target'] = target_list\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0HBs3yUXJIB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save Data\n",
        "\n",
        "Colaboratory allows us to save data to the \"Download\" folder of the computer through this approach."
      ]
    },
    {
      "metadata": {
        "id": "VxAt014yv2e6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "filename_out = 'df3.csv'\n",
        "\n",
        "df3.to_csv(filename_out)  # Save to .csv format\n",
        "files.download(filename_out) # Export to Downloads folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T48OiwMG_vet",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}